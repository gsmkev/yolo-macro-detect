#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Pipeline de Detecci√≥n de Macroinvertebrados Acu√°ticos
====================================================

Pipeline completo para detecci√≥n de macroinvertebrados usando YOLOv8.
Incluye descarga de dataset, entrenamiento, evaluaci√≥n e inferencia
con c√°lculo autom√°tico del √≠ndice BMWP para evaluaci√≥n de calidad del agua.

Autor: Kevin Galeano
Proyecto: PINV01-1159
Fecha: 2024
"""

import argparse
import sys
from pathlib import Path
from typing import Optional

from config import config
from data import DatasetManager
from models import YOLOTrainer, YOLOInference
from utils.logger import setup_logger


class MacroinvertebratePipeline:
    """
    Pipeline completo para detecci√≥n de macroinvertebrados acu√°ticos.
    
    Esta clase maneja todo el flujo de trabajo desde la descarga del dataset
    hasta la inferencia con modelos entrenados, incluyendo evaluaci√≥n de
    calidad del agua mediante el √≠ndice BMWP.
    """
    
    def __init__(self):
        """Inicializa el pipeline."""
        self.logger = setup_logger("macroinvertebrate_pipeline")
        self.dataset_manager = DatasetManager()
        self.trainer = None
        self.inference = None
        
        # Validar configuraci√≥n
        if not config.validate():
            self.logger.error("‚ùå Configuraci√≥n inv√°lida. Revisa tu archivo .env")
            sys.exit(1)
        
        self.logger.info("‚úÖ Pipeline inicializado correctamente")
        self.logger.info(str(config))
    
    def setup_dataset(self, version: Optional[int] = None) -> str:
        """
        Configura y descarga el dataset.
        
        Args:
            version: Versi√≥n espec√≠fica del dataset (opcional)
            
        Returns:
            Ruta al archivo data.yaml
        """
        self.logger.info("üì• Configurando dataset...")
        
        try:
            # Configurar conexi√≥n con Roboflow
            self.dataset_manager.setup_roboflow_connection()
            
            # Descargar dataset
            dataset_info = self.dataset_manager.download_dataset(version=version)
            
            # Validar estructura
            self.dataset_manager.validate_dataset_structure(dataset_info["location"])
            
            # Generar data.yaml
            data_yaml_path = self.dataset_manager.generate_data_yaml(dataset_info["location"])
            
            self.logger.info(f"‚úÖ Dataset configurado exitosamente")
            self.logger.info(f"   - Ubicaci√≥n: {dataset_info['location']}")
            self.logger.info(f"   - data.yaml: {data_yaml_path}")
            
            return data_yaml_path
            
        except Exception as e:
            self.logger.error(f"‚ùå Error configurando dataset: {e}")
            raise
    
    def train_model(self, 
                   data_yaml_path: str,
                   experiment_name: Optional[str] = None,
                   epochs: Optional[int] = None) -> str:
        """
        Entrena el modelo YOLO.
        
        Args:
            data_yaml_path: Ruta al archivo data.yaml
            experiment_name: Nombre del experimento
            epochs: N√∫mero de √©pocas
            
        Returns:
            Ruta al modelo entrenado
        """
        self.logger.info("üèãÔ∏è Iniciando entrenamiento del modelo...")
        
        try:
            # Inicializar trainer
            experiment_name = experiment_name or config.experiment_name
            self.trainer = YOLOTrainer(experiment_name)
            
            # Cargar modelo base
            self.trainer.load_model(config.model_name)
            
            # Entrenar modelo
            model_path = self.trainer.train(
                data_yaml_path=data_yaml_path,
                epochs=epochs or config.training_epochs,
                img_size=config.img_size,
                batch_size=config.batch_size,
                workers=config.workers
            )
            
            # Evaluar modelo
            self.logger.info("üìä Evaluando modelo entrenado...")
            metrics = self.trainer.evaluate(model_path, data_yaml_path)
            
            # Obtener resumen
            summary = self.trainer.get_training_summary()
            self.logger.info(f"üìà Resumen del entrenamiento:")
            self.logger.info(f"   - mAP50: {summary['metrics']['map50']:.4f}")
            self.logger.info(f"   - Precisi√≥n: {summary['metrics']['precision']:.4f}")
            self.logger.info(f"   - Recall: {summary['metrics']['recall']:.4f}")
            
            return model_path
            
        except Exception as e:
            self.logger.error(f"‚ùå Error durante el entrenamiento: {e}")
            raise
    
    def run_complete_pipeline(self, 
                            version: Optional[int] = None,
                            epochs: Optional[int] = None,
                            experiment_name: Optional[str] = None) -> str:
        """
        Ejecuta el pipeline completo.
        
        Args:
            version: Versi√≥n del dataset
            epochs: N√∫mero de √©pocas
            experiment_name: Nombre del experimento
            
        Returns:
            Ruta al modelo entrenado
        """
        self.logger.info("üöÄ Iniciando pipeline completo...")
        
        try:
            # 1. Configurar dataset
            data_yaml_path = self.setup_dataset(version=version)
            
            # 2. Entrenar modelo
            model_path = self.train_model(
                data_yaml_path=data_yaml_path,
                experiment_name=experiment_name,
                epochs=epochs
            )
            
            self.logger.info("üéâ Pipeline completo finalizado exitosamente!")
            return model_path
            
        except Exception as e:
            self.logger.error(f"‚ùå Error en pipeline completo: {e}")
            raise
    
    def predict_image(self, 
                     image_path: str,
                     model_path: str,
                     conf_threshold: Optional[float] = None,
                     save_annotated: bool = True,
                     calculate_bmwp: bool = False) -> dict:
        """
        Realiza predicci√≥n en una imagen.
        
        Args:
            image_path: Ruta a la imagen
            model_path: Ruta al modelo entrenado
            conf_threshold: Umbral de confianza
            save_annotated: Si guardar imagen anotada
            calculate_bmwp: Si calcular el √≠ndice BMWP
            
        Returns:
            Resultados de la predicci√≥n
        """
        self.logger.info(f"üîç Realizando predicci√≥n en: {image_path}")
        
        try:
            # Inicializar inferencia
            self.inference = YOLOInference(model_path)
            
            # Realizar predicci√≥n
            results = self.inference.predict_image(
                image_path=image_path,
                conf_threshold=conf_threshold,
                save_annotated=save_annotated,
                calculate_bmwp=calculate_bmwp
            )
            
            # Exportar resultados
            output_file = f"results/prediction_{Path(image_path).stem}.json"
            self.inference.export_results(results, output_file)
            
            return results
            
        except Exception as e:
            self.logger.error(f"‚ùå Error durante la predicci√≥n: {e}")
            raise


def main():
    """
    Funci√≥n principal del script.
    
    Maneja los argumentos de l√≠nea de comandos y ejecuta
    las operaciones correspondientes.
    """
    parser = argparse.ArgumentParser(
        description="Pipeline de Detecci√≥n de Macroinvertebrados Acu√°ticos",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Ejemplos de uso:

  # Pipeline completo
  python main.py --pipeline-complete

  # Solo configurar dataset
  python main.py --setup-dataset

  # Solo entrenamiento
  python main.py --train --data-yaml datasets/data.yaml

  # Solo predicci√≥n
  python main.py --predict --image test.jpg --model runs/detect/macros/weights/best.pt

  # Predicci√≥n con c√°lculo BMWP
  python main.py --predict --image sample.jpg --model best_model.pt --calculate-bmwp
        """
    )
    
    # Argumentos principales
    parser.add_argument(
        "--pipeline-complete",
        action="store_true",
        help="Ejecutar pipeline completo (dataset + entrenamiento)"
    )
    
    parser.add_argument(
        "--setup-dataset",
        action="store_true",
        help="Solo configurar y descargar dataset"
    )
    
    parser.add_argument(
        "--train",
        action="store_true",
        help="Solo entrenar modelo"
    )
    
    parser.add_argument(
        "--predict",
        action="store_true",
        help="Solo realizar predicci√≥n"
    )
    
    # Argumentos de configuraci√≥n
    parser.add_argument(
        "--dataset-version",
        type=int,
        help="Versi√≥n espec√≠fica del dataset"
    )
    
    parser.add_argument(
        "--epochs",
        type=int,
        help="N√∫mero de √©pocas para entrenamiento"
    )
    
    parser.add_argument(
        "--experiment-name",
        type=str,
        help="Nombre del experimento"
    )
    
    parser.add_argument(
        "--data-yaml",
        type=str,
        help="Ruta al archivo data.yaml"
    )
    
    parser.add_argument(
        "--image",
        type=str,
        help="Ruta a la imagen para predicci√≥n"
    )
    
    parser.add_argument(
        "--model",
        type=str,
        help="Ruta al modelo entrenado"
    )
    
    parser.add_argument(
        "--confidence",
        type=float,
        help="Umbral de confianza para predicci√≥n"
    )
    
    # Argumentos adicionales
    parser.add_argument(
        "--save-annotated",
        action="store_true",
        default=True,
        help="Guardar imagen anotada (por defecto: True)"
    )
    
    parser.add_argument(
        "--calculate-bmwp",
        action="store_true",
        help="Calcular √≠ndice BMWP para evaluaci√≥n de calidad del agua"
    )
    
    parser.add_argument(
        "--output-dir",
        type=str,
        default="results",
        help="Directorio de salida (por defecto: results)"
    )
    
    args = parser.parse_args()
    
    # Inicializar pipeline
    pipeline = MacroinvertebratePipeline()
    
    try:
        if args.pipeline_complete:
            # Pipeline completo
            model_path = pipeline.run_complete_pipeline(
                version=args.dataset_version,
                epochs=args.epochs,
                experiment_name=args.experiment_name
            )
            print(f"\nüéâ Pipeline completado! Modelo guardado en: {model_path}")
            
        elif args.setup_dataset:
            # Solo configurar dataset
            data_yaml_path = pipeline.setup_dataset(version=args.dataset_version)
            print(f"\n‚úÖ Dataset configurado! data.yaml en: {data_yaml_path}")
            
        elif args.train:
            # Solo entrenamiento
            if not args.data_yaml:
                print("‚ùå Error: --data-yaml es requerido para entrenamiento")
                sys.exit(1)
            
            model_path = pipeline.train_model(
                data_yaml_path=args.data_yaml,
                experiment_name=args.experiment_name,
                epochs=args.epochs
            )
            print(f"\n‚úÖ Entrenamiento completado! Modelo guardado en: {model_path}")
            
        elif args.predict:
            # Solo predicci√≥n
            if not args.image or not args.model:
                print("‚ùå Error: --image y --model son requeridos para predicci√≥n")
                sys.exit(1)
            
            results = pipeline.predict_image(
                image_path=args.image,
                model_path=args.model,
                conf_threshold=args.confidence,
                save_annotated=args.save_annotated,
                calculate_bmwp=args.calculate_bmwp
            )
            
            print(f"\nüîç Predicci√≥n completada!")
            print(f"   - Total detecciones: {results['total_detecciones']}")
            print(f"   - Familias detectadas: {results['familias_detectadas']}")
            
            for det in results['detecciones']:
                print(f"   - {det['familia']}: {det['cantidad']} (conf: {det['confidence_promedio']:.3f})")
            
            # Mostrar resultados BMWP si se calcul√≥
            if args.calculate_bmwp and 'bmwp_total' in results:
                print(f"\nüåä Evaluaci√≥n de Calidad del Agua (BMWP):")
                print(f"   - Puntaje total: {results['bmwp_total']}")
                print(f"   - Calidad del agua: {results['calidad_agua']}")
                print(f"   - Confianza: {results['confianza']:.3f}")
                
                if results['detalles_familias']:
                    print(f"   - Detalles por familia:")
                    for det in results['detalles_familias']:
                        print(f"     * {det['familia']}: {det['cantidad']} (BMWP: {det['bmwp']})")
                
        else:
            # Mostrar ayuda si no se especifican argumentos
            parser.print_help()
            
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Operaci√≥n cancelada por el usuario")
        sys.exit(1)
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main() 